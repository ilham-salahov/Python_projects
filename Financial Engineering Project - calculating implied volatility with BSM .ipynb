{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: py_vollib in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: simplejson in c:\\users\\dell\\anaconda3\\lib\\site-packages (from py_vollib) (3.17.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from py_vollib) (1.19.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\dell\\anaconda3\\lib\\site-packages (from py_vollib) (1.1.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from py_vollib) (1.5.2)\n",
      "Requirement already satisfied: py-lets-be-rational in c:\\users\\dell\\anaconda3\\lib\\site-packages (from py_vollib) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas->py_vollib) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas->py_vollib) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->py_vollib) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install py_vollib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import shapiro\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "import warnings\n",
    "import matplotlib as mpl\n",
    "plt.style.use('seaborn')\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Underlying Asset: S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "asset = yf.download(\"^GSPC\", start= \"2016-06-17\", end=\"2021-06-17\")\n",
    "asset = pd.DataFrame(asset[\"Close\"].dropna())\n",
    "asset1 = yf.download(\"^GSPC\", start= \"2020-07-03\", end=\"2021-07-03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Time - series analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Log-normal properity of GBM\n",
    "We know that stock prices follow a Geometric Brownian Motion. One of the properties of GBM is that stock prices are log-normal.\n",
    "Hence, logarithm of stock prices are normally distributed.In what follows we will try to show that if log returns of the stock prices have normal distribution. We do this for different time lengths - 1, 2 and 5 years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now calculate log-returns, $\\mu, \\sigma$ and check for normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_returns = np.log(asset/asset.shift(1))\n",
    "asset_returns = asset_returns.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating $\\mu, \\sigma$ for 1, 2 and 5 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_mean_1 = asset_returns[\"2020-06-17\":\"2021-06-17\"].mean()\n",
    "daily_mean_2 = asset_returns[\"2019-06-17\":\"2021-06-17\"].mean()\n",
    "daily_mean_5 = asset_returns[\"2016-06-17\":\"2021-06-17\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_std_1 = asset_returns[\"2020-06-17\":\"2021-06-17\"].std()\n",
    "daily_std_2 = asset_returns[\"2019-06-17\":\"2021-06-17\"].std()\n",
    "daily_std_5 = asset_returns[\"2016-06-17\":\"2021-06-17\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize = (18,5))\n",
    "\n",
    "x1 = np.arange(-0.24,0.2, 0.001)\n",
    "x2 = np.arange(-0.22,0.2, 0.001)\n",
    "x3 = np.arange(-0.2,0.2, 0.001)\n",
    "\n",
    "ax[0].hist(asset_returns[\"2020-06-17\":\"2021-06-17\"], bins = 100)\n",
    "ax[0].plot(x1, stats.norm.pdf(x1, daily_mean_1, daily_std_1))\n",
    "ax[0].set_title(\"1 Year Returns\")\n",
    "\n",
    "ax[1].hist(asset_returns[\"2019-06-17\":\"2021-06-17\"], bins = 100)\n",
    "ax[1].plot(x2, stats.norm.pdf(x2, daily_mean_2, daily_std_2))\n",
    "ax[1].set_title(\"2 Year Returns\")\n",
    "\n",
    "ax[2].hist(asset_returns[\"2016-06-17\":\"2021-06-17\"], bins = 100)\n",
    "ax[2].plot(x3, stats.norm.pdf(x3, daily_mean_5, daily_std_5))\n",
    "ax[2].set_title(\"5 Year Returns\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the histograms we can see that returns for 1, 2 and 5 years seem to be not normally distributed, but, in order to prove normality we do a more rigorous test - Shapiro - Wilk test\n",
    "\n",
    "The Shapiro-Wilk test evaluates a data sample and quantifies how likely it is that the data was drawn from a Gaussian distribution\n",
    "\n",
    "- p < 0.05, reject H0 - not normal\n",
    "\n",
    "- p > 0.05, fail to reject H0 - normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = shapiro(asset_returns[\"2020-06-17\":\"2021-06-17\"])\n",
    "print(f\"p value for 1 year returns: {p}\")\n",
    "stat, p = shapiro(asset_returns[\"2019-06-17\":\"2021-06-17\"])\n",
    "print(f\"p value for 2 year returns: {p}\")\n",
    "stat, p = shapiro(asset_returns[\"2016-06-17\":\"2021-06-17\"])\n",
    "print(f\"p value for 5 year returns: {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p values for all all the time lengths are less than 0.05. Hence, we reject the H0 and confirm that our data sets are not normaly distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Markov properity of GBM\n",
    "A Markov process is a particular type of stochastic process where only the current value of a variable is relevant for predicting the future. So, in our case past history of our variable should be irrelevat to predict the future values.We should be able to use only present data to make a prediction about tomorrow's price. We can use plot_acf and plot_pacf functions to see the relationship between todays stock rices and past prices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,2, figsize = (16,12))\n",
    "plot_acf(asset[\"2020-06-17\":\"2021-06-17\"], ax = axes[0,0]) \n",
    "axes[0,0].set_title(\"Autocorrelation for 1-year stock prices\")\n",
    "\n",
    "plot_acf(asset[\"2019-06-17\":\"2021-06-17\"], ax = axes[1,0])   \n",
    "axes[1,0].set_title(\"Autocorrelation for 2-year stock prices\")\n",
    "\n",
    "plot_acf(asset[\"2016-06-17\":\"2021-06-17\"], ax = axes[2,0])\n",
    "axes[2,0].set_title(\"Autocorrelation for 5-year stock prices\")\n",
    "\n",
    "\n",
    "\n",
    "plot_pacf(asset[\"2020-06-17\":\"2021-06-17\"], ax = axes[0,1])   \n",
    "axes[0,1].set_title(\"Partial Autocorrelation for 1-year stock prices\")\n",
    "\n",
    "plot_pacf(asset[\"2019-06-17\":\"2021-06-17\"], ax = axes[1,1])  \n",
    "axes[1,1].set_title(\"Partial Autocorrelation for 2-year stock prices\")\n",
    "\n",
    "plot_pacf(asset[\"2016-06-17\":\"2021-06-17\"], ax = axes[2,1])\n",
    "axes[2,1].set_title(\"Partial Autocorrelation for 5-year stock prices\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- plot_acf function gives us autocorrolation - correlation of a given time series with its lagged version of itself. Here we have direct and indirect effects of lagged versions\n",
    "- plot_pacf function gives us partial autocorrelation - at lag k, this is the correlation between series values that are k intervals apart. In partial autocorrelation indirect effects have been removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a strong autocorrelation of our time series with its lagged versions, but, this correlation is getting smaller as the number of laggs increase.\n",
    "\n",
    "The main finding comes from partial autocorrelation function. It is clear that only present value of the stock price is relevat to make a prediction about tommorow's price. If we consider the first lag - St - as the future value and the second lag - S0 - as present value. It is only S0 that we can use as a predictor for St. All the remaining past prices -lags - have statistically insignificant correlation with St. This backs up Markov process - only the current value of a variable is relevant for predicting the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Continuous sample path properity of GBM\n",
    "Sample path of GBM is continuous as a function of time and jagged. A continuous function is a function that does not have any abrupt changes in value  and there are no breaking points - discontinuities. A GBM function is also very jagged. No matter how much we zoom in, we can still observe jagged patterns. Such a function is also non-differentiable. Next we plot our asset to see if it has these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize = (18,5))\n",
    "ax[0].plot(asset[\"2020-06-17\":\"2021-06-17\"])\n",
    "ax[0].set_title(\"1 Year Prices\")\n",
    "ax[0].set_ylabel(\"Price\")\n",
    "ax[0].set_xlabel(\"Time\")\n",
    "\n",
    "ax[1].plot(asset[\"2019-06-17\":\"2021-06-17\"])\n",
    "ax[1].set_title(\"2 Year Prices\")\n",
    "ax[1].set_ylabel(\"Price\")\n",
    "ax[1].set_xlabel(\"Time\")\n",
    "\n",
    "ax[2].plot(asset[\"2016-06-17\":\"2021-06-17\"])\n",
    "ax[2].set_title(\"5 Year Prices\")\n",
    "ax[2].set_ylabel(\"Price\")\n",
    "ax[2].set_xlabel(\"Time\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, we can clearly see that sample path of our asset is extremely jagged and continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that even though our underlying asset returns are not normally distributed (however they resemble normal distribution symetry), it is in fact a Markov process and its sample path is a continuous function of time and jagged. Based on what we observe above we assume that our underlying asset follows a geometric Brownian Motion and proceed to the second part - finding implyed volatility with Black-Scholes-Merton formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  2 Finding Implied Volatility\n",
    "Implied volatility is calculated by taking the market price of the option, entering it into the Black-Scholes formula, and back-solving for the value of the volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Black-Scholes-Merton formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to implement Black-Scholes formula:\n",
    "\\begin{equation}C = N(d_{1})Sd_{t} - N(d_{2})Ke^{-rt}\\end{equation}\n",
    "\n",
    "\\begin{equation}d_{1} = \\frac{ln(\\frac{S_{t}}{K})+(r+\\frac{\\sigma^2}{2})}{\\sigma\\sqrt{t}} \\end{equation}\n",
    "\n",
    "\\begin{equation}d_{2} = d_{1} - \\sigma\\sqrt{t} \\end{equation}\n",
    "\n",
    "- S0: value of underlying\n",
    "- K: strike price\n",
    "- T: time to maturity (year fraction)\n",
    "- r: risk free rate\n",
    "- sigma_est: estimated value for sigma - to initiate the process\n",
    "- sigma: volatility factor (historical volatility)\n",
    "- C0: market value of option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_value(S0, K, T, r, sigma):\n",
    "    S0 = float(S0)\n",
    "    d1 = (math.log(S0 / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * math.sqrt(T))\n",
    "    d2 = (math.log(S0 / K) + (r - 0.5 * sigma ** 2) * T) / (sigma * math.sqrt(T))\n",
    "    value = (S0 * stats.norm.cdf(d1, 0.0, 1.0) - K * math.exp(-r * T) * stats.norm.cdf(d2, 0.0, 1.0))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- call_value function implements Black-Scholes-Merton formula and finds the value of European call option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vega(S0, K, T, r, sigma):\n",
    "    S0 = float(S0)\n",
    "    d1 = (math.log(S0 / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * math.sqrt(T))\n",
    "    vega = S0 * stats.norm.pdf(d1, 0.0, 1.0) * math.sqrt(T)\n",
    "    return vega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vega is the Greek that measures an option’s sensitivity to implied volatility\n",
    "- It is the change in the option’s price for a one-point change in implied volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formula for implied vaolatility:\n",
    "\n",
    "\\begin{equation}\\sigma_{iv} = \\frac{C-C_{0}}{V} \\end{equation}\n",
    "\n",
    "- C: Calculated value, using BSM formula\n",
    "- C0: Market value\n",
    "- V: Vega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imp_vol(S0, K, T, r, C0, sigma_estimate, it=400):\n",
    "    for i in range(it):\n",
    "        sigma_estimate -= ((call_value(S0, K, T, r, sigma_estimate) - C0) / vega(S0, K, T, r, sigma_estimate))\n",
    "        return sigma_estimate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What we are doing here is basically giving call_value function our estimated volatility - sigma_estimate and other parameters to get the value of option. Because we have the real value of the option - C0 we can see if sigma_estimate is close enough to the real implied volatility which would give us the real value of the option(C0). We find value of the option with call_value and deduct C0 from it and divide the result by vega. We do this process 100 times - trail and error. When the value from this eqaution is 0, this will be the real implied volatility - at least something very close to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Applying BSM formula to find implied volatililty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use our functions to find the implied volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Underlying: S&P 500\n",
    "- Option:SPX\n",
    "- Symbol:SPXW210806C04340000 \n",
    "- Strike:4340\n",
    "- Price: 59.12\n",
    "- Expiration date: Fri Aug 06 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Because our option's expiration date is one month away, we use 1 month US treasury rate as risk free rate which is 0.048%\n",
    "\n",
    "- Data has been taken from https://www.cboe.com/\n",
    "\n",
    "- This data has been taken 2 July, 2021 and is subject to change. This would mean that implied volatility found here might be different than the implied volatility calculated at a different future time and to get the right iplied volatility parameters should be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "S0 = 15    \n",
    "K = 13\n",
    "T = 0.25\n",
    "r = 0.05\n",
    "sigma = 0\n",
    "sigma_estimate = 0.4\n",
    "C0 = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_vol = imp_vol(S0, K, T, r, C0, sigma_estimate, it=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model implied volatility: 39.6445%\n",
      "Real implied volatility: 11%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model implied volatility: {(100*imp_vol).round(4)}%\")\n",
    "print(f\"Real implied volatility: 11%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
